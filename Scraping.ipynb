{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27bae51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd12868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing the page to search for links...\n",
      "Found 11 unique files to process.\n",
      "Downloading 2025 (Attempt 1/5)...\n",
      "--- Success processing the file for 2025!\n",
      "Downloading 2024 (Attempt 1/5)...\n",
      "!!! Error on attempt 1 for year 2024: ('Connection broken: IncompleteRead(3520668 bytes read, 23352920 more expected)', IncompleteRead(3520668 bytes read, 23352920 more expected))\n",
      "Waiting 2 seconds for a new attempt...\n",
      "Downloading 2024 (Attempt 2/5)...\n",
      "--- Success processing the file for 2024!\n",
      "Downloading 2023 (Attempt 1/5)...\n"
     ]
    }
   ],
   "source": [
    "def download_sinesp(max_retries=5, delay=3):\n",
    "    \"\"\"\n",
    "    Accesses the SINESP page, extracts spreadsheet links, and consolidates them into a DataFrame.\n",
    "    \n",
    "    :param max_retries: Number of times the script will attempt to download each file in case of error.\n",
    "    :param delay: Seconds to wait between download attempts.\n",
    "    \"\"\"\n",
    "    url_base = \"https://www.gov.br/mj/pt-br/assuntos/sua-seguranca/seguranca-publica/estatistica/dados-nacionais-1/base-de-dados-e-notas-metodologicas-dos-gestores-estaduais-sinesp-vde-2022-e-2023\"\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    print(\"Accessing the page to search for links...\")\n",
    "    try:\n",
    "        response = requests.get(url_base, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error accessing the main page: {e}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Collect all links pointing to Excel files of type 'bancovde'\n",
    "    links_encontrados = []\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        href = a['href']\n",
    "        if 'bancovde' in href and 'xlsx' in href:\n",
    "            # Ensure the link is absolute\n",
    "            if not href.startswith('http'):\n",
    "                href = requests.compat.urljoin(url_base, href)\n",
    "            links_encontrados.append(href)\n",
    "    \n",
    "    # Remove duplicates while maintaining order\n",
    "    links = list(dict.fromkeys(links_encontrados))\n",
    "    print(f\"Found {len(links)} unique files to process.\")\n",
    "\n",
    "    dataframes = []\n",
    "\n",
    "    for link in links:\n",
    "        # Try to extract the year from the link for logging purposes\n",
    "        ano_match = re.search(r'bancovde-(\\d{4})', link)\n",
    "        year = ano_match.group(1) if ano_match else \"Unknown\"\n",
    "        \n",
    "        download_success = False\n",
    "        \n",
    "        # Start of the retry logic routine\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            try:\n",
    "                print(f\"Downloading {year} (Attempt {attempt}/{max_retries})...\")\n",
    "                r = requests.get(link, headers=headers, timeout=60)\n",
    "                r.raise_for_status() # Raises an error if status is not 200\n",
    "                \n",
    "                # If it reached here, the download worked. Reading the Excel:\n",
    "                df_year = pd.read_excel(io.BytesIO(r.content))\n",
    "                df_year['ano_referencia_arquivo'] = year\n",
    "                \n",
    "                dataframes.append(df_year)\n",
    "                print(f\"--- Success processing the file for {year}!\")\n",
    "                download_success = True\n",
    "                break # Exit the retry loop and move to the next link\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"!!! Error on attempt {attempt} for year {year}: {e}\")\n",
    "                if attempt < max_retries:\n",
    "                    print(f\"Waiting {delay} seconds for a new attempt...\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    print(f\"XXX Final failure for file {year} after {max_retries} attempts.\")\n",
    "\n",
    "    if dataframes:\n",
    "        print(\"\\nConsolidating all years into a single DataFrame...\")\n",
    "        df_final = pd.concat(dataframes, ignore_index=True)\n",
    "        print(f\"Completed! Total records: {df_final.shape[0]}\")\n",
    "        return df_final\n",
    "    else:\n",
    "        print(\"No data was successfully downloaded.\")\n",
    "        return None\n",
    "\n",
    "# Script Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the max_retries here\n",
    "    df_consolidated = download_sinesp(max_retries=5, delay=2)\n",
    "    \n",
    "    if df_consolidated is not None:\n",
    "        # Display the first few rows of the final result\n",
    "        print(df_consolidated.head())\n",
    "        \n",
    "        # Optional: Save to CSV\n",
    "        #df_consolidated.to_csv(\"sinesp_2015_2025_consolidated.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CrimesEnv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
